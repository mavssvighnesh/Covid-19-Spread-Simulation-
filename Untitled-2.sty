
@book{21,
	title = {Feature {Engineering} for {Machine} {Learning} and {Data} {Analytics}},
	isbn = {978-1-351-72127-1},
	abstract = {Feature engineering plays a vital role in big data analytics. Machine learning and data mining algorithms cannot work without data. Little can be achieved if there are few features to represent the underlying data objects, and the quality of results of those algorithms largely depends on the quality of the available features. Feature Engineering for Machine Learning and Data Analytics provides a comprehensive introduction to feature engineering, including feature generation, feature extraction, feature transformation, feature selection, and feature analysis and evaluation. The book presents key concepts, methods, examples, and applications, as well as chapters on feature engineering for major data types such as texts, images, sequences, time series, graphs, streaming data, software engineering data, Twitter data, and social media data. It also contains generic feature generation approaches, as well as methods for generating tried-and-tested, hand-crafted, domain-specific features.The first chapter defines the concepts of features and feature engineering, offers an overview of the book, and provides pointers to topics not covered in this book. The next six chapters are devoted to feature engineering, including feature generation for specific data types. The subsequent four chapters cover generic approaches for feature engineering, namely feature selection, feature transformation based feature engineering, deep learning based feature engineering, and pattern based feature generation and engineering. The last three chapters discuss feature engineering for social bot detection, software management, and Twitter-based applications respectively.This book can be used as a reference for data analysts, big data scientists, data preprocessing workers, project managers, project developers, prediction modelers, professors, researchers, graduate students, and upper level undergraduate students. It can also be used as the primary text for courses on feature engineering, or as a supplement for courses on machine learning, data mining, and big data analytics.},
	language = {en},
	publisher = {CRC Press},
	author = {Dong, Guozhu and Liu, Huan},
	month = mar,
	year = {2018},
	note = {Google-Books-ID: 661SDwAAQBAJ},
	keywords = {Business \& Economics / Statistics, Computers / Artificial Intelligence / General, Computers / Data Science / Data Analytics, Computers / Machine Theory, Computers / Programming / Games, Mathematics / Probability \& Statistics / General, Technology \& Engineering / Automation},
}

@article{10,
	title = {Dimensionality {Reduction}: {A} {Comparative} {Review}},
	abstract = {In recent years, a variety of nonlinear dimensionality reduction techniques have been proposed that aim to address the limitations of traditional techniques such as PCA and classical scaling. The paper presents a review and systematic comparison of these techniques. The performances of the nonlinear techniques are investigated on artiﬁcial and natural tasks. The results of the experiments reveal that nonlinear techniques perform well on selected artiﬁcial tasks, but that this strong performance does not necessarily extend to real-world tasks. The paper explains these results by identifying weaknesses of current nonlinear techniques, and suggests how the performance of nonlinear dimensionality reduction techniques may be improved.},
	language = {en},
	author = {Tr, TiCC},
	file = {PDF:C\:\\Users\\vighn\\Zotero\\storage\\EG23HHNP\\Tr - Dimensionality Reduction A Comparative Review.pdf:application/pdf},
}
@misc{11,
author={geeksforgeeks}
	title = {{ML} {\textbar} {Underfitting} and {Overfitting} - {GeeksforGeeks}},
	url = {https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/},
	urldate = {2024-09-19},
	file = {ML | Underfitting and Overfitting - GeeksforGeeks:C\:\\Users\\vighn\\Zotero\\storage\\7SBV2N2T\\underfitting-and-overfitting-in-machine-learning.html:text/html},
}

@inproceedings{15,
	title = {Carbon emissions allowances trade amount dynamic prediction based on machine learning},
	url = {https://ieeexplore.ieee.org/document/9763576},
	doi = {10.1109/MLKE55170.2022.00028},
	abstract = {With the increasing threatening of the greenhouse effect, taking some measures to reduce carbon emissions is extremely essential. Carbon pricing policy is one of the most powerful tools for reducing emissions. However, most researches focused on carbon emissions allowances trade price prediction, only few investigations paid attention to carbon emissions allowances trade volume prediction. In order to better understand carbon emissions of carbon emissions, this study performed long-term prediction and short-term prediction models to predict carbon emissions trading volume. Linear regression, Decision tree, Random forest, Extreme gradient boosting and Support vector machine were chosen to perform long-term prediction. In these five long-term prediction models, Random Forest performs best with the smallest mean absolute error (24.42). What’s more, a time series forward multi-step hybrid intelligent prediction model (consists of reinforcement learning model, hidden Markov model and neural network) was used to perform short-term prediction, which improves the accuracy and effect of the prediction. The mean absolute error of short-term prediction is 6.79. Our study shows there is a nonlinear relationship between the lag of volume/frequency of transactions and price in the future. The machine learning-based Carbon emissions allowances trade prediction enables traders and environmental organizations to observe the overall carbon emissions trading volume trends and changes as well as judge the short-term trading situation and make judgments.},
	urldate = {2024-10-01},
	booktitle = {2022 {International} {Conference} on {Machine} {Learning} and {Knowledge} {Engineering} ({MLKE})},
	author = {Wong, Fongyiu},
	month = feb,
	year = {2022},
	keywords = {Carbon dioxide, carbon emissions allowances trade, Emissions trading, Hidden Markov models, long-term prediction, Reinforcement learning, short-term prediction models, Solid modeling, Support vector machines, Time series analysis},
	pages = {115--120},
}

@inproceedings{16,
	title = {Predictive {Modeling} of {Vehicle} {CO2} {Emissions} {Using} {Machine} {Learning} {Techniques}: {A} {Comprehensive} {Analysis} of {Automotive} {Attributes}},
	shorttitle = {Predictive {Modeling} of {Vehicle} {CO2} {Emissions} {Using} {Machine} {Learning} {Techniques}},
	url = {https://ieeexplore.ieee.org/document/10390183},
	doi = {10.1109/ICTACS59847.2023.10390183},
	abstract = {Concerns about protecting the environment and reducing the negative effects of greenhouse gas emissions, particularly in the automotive industry, have raised interest in finding creative and innovative ways to reduce carbon dioxide (CO2) emissions from a variety of sources. This study paper delves deeper into the intriguing possibilities of using machine learning (ML) techniques to predict the amount of CO2 emitted by cars. We are exploring the subject of machine learning to develop a system that can forecast CO2 emissions based on many parameters. Important information about the vehicle, including its make, model, type, number of cylinders, engine size, gearbox type, fuel type, fuel consumption on highways and in cities, and CO2 emission levels, are included in the dataset that serves as the foundation for our study. The creation of accurate and dependable prediction models capable of estimating CO2 emissions from cars is the main goal of this research. Environmental policymakers, customers, and manufacturers may all benefit greatly from these models. To do this, we employ a variety of machine learning (ML) techniques, including ensemble methods, neural networks, decision trees, and regression algorithms, among others. We evaluate the prediction accuracy, scenario handling flexibility, and information processing efficiency of several systems through this study. We determine which machine learning models are most suited for predicting CO2 emissions within the parameters of the given dataset by applying a methodical evaluation approach. Furthermore, we investigate the influence of different feature subsets on prediction performance, shedding light on the relative importance of various vehicle attributes in determining CO2 emissions. Our findings not only contribute to advancing the field of predictive emissions modeling but also offer insights into the key factors driving vehicle-related CO2 emissions.},
	urldate = {2024-10-01},
	booktitle = {2023 3rd {International} {Conference} on {Technological} {Advancements} in {Computational} {Sciences} ({ICTACS})},
	author = {Satpute, Babasaheb S. and Bharati, Rajesh and Rahane, Wasudeo P.},
	month = nov,
	year = {2023},
	keywords = {Artificial Intelligence, Automobiles, Automotive, Climate, CO2 Emission, Environment, Fuels, Green products, Machine learning, Machine Learning, Predictive models, Road transportation, Urban areas},
	pages = {511--516},
}


@inproceedings{17,
	title = {Prediction {Model}: {CO2} {Emission} {Using} {Machine} {Learning}},
	shorttitle = {Prediction {Model}},
	url = {https://ieeexplore.ieee.org/document/8529498},
	doi = {10.1109/I2CT.2018.8529498},
	abstract = {The paper provides insight of CO2 emission prediction model using machine learning. Traditionally researchers have used statistical techniques such as regression, t-test, derivation, ANOVA Test for prediction. The Machine learning provides different techniques to train the machine based on experience. In this paper Supervised Machine learning regression technique is used for the prediction of CO2 emission. In this paper an iterative and continuous improvement approach will be adapted to achieve successful results. The results are validated using Root Mean Square Error(RMSE) technique.},
	urldate = {2024-10-01},
	booktitle = {2018 3rd {International} {Conference} for {Convergence} in {Technology} ({I2CT})},
	author = {Kadam, Pooja and Vijayumar, Suhasini},
	month = apr,
	year = {2018},
	keywords = {Carbon dioxide, carbon emission, CO2, Dairy products, Data models, GHG, machine learning, Machine learning, prediction, Predictive models, RMSE, Testing, Training},
	pages = {1--3},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\vighn\\Zotero\\storage\\ZTFBU4KH\\8529498.html:text/html},
}

@inproceedings{7,
	address = {Berlin, Heidelberg},
	title = {Support {Vector} {Machine} {Classification} {Algorithm} and {Its} {Application}},
	isbn = {978-3-642-34041-3},
	doi = {10.1007/978-3-642-34041-3_27},
	abstract = {The support vector machine is a new type of machine learning methods based on statistical learning theory. Because of good promotion and a higher accuracy, support vector machine has become the research focus of the machine learning community. This paper introduces the basic theory of support vector machine, the basic idea of the classification and currently used support vector machine classification algorithm. Practical problems with which an algorithm, and proves the effectiveness of the algorithm, the final outlook of the prospects of support vector machines in classification applications. Finally the prospect of the prospect of support vector machines in classification applications.},
	language = {en},
	booktitle = {Information {Computing} and {Applications}},
	publisher = {Springer},
	author = {Zhang, Yongli},
	editor = {Liu, Chunfeng and Wang, Leizhen and Yang, Aimin},
	year = {2012},
	pages = {179--186},
}

@article{18,
	title = {A {Survey} of {Accuracy} {Evaluation} {Metrics} of {Recommendation} {Tasks}},
	abstract = {Recommender systems are now popular both commercially and in the research community, where many algorithms have been suggested for providing recommendations. These algorithms typically perform differently in various domains and tasks. Therefore, it is important from the research perspective, as well as from a practical view, to be able to decide on an algorithm that matches the domain and the task of interest. The standard way to make such decisions is by comparing a number of algorithms ofﬂine using some evaluation metric. Indeed, many evaluation metrics have been suggested for comparing recommendation algorithms. The decision on the proper evaluation metric is often critical, as each metric may favor a different algorithm. In this paper we review the proper construction of ofﬂine experiments for deciding on the most appropriate algorithm. We discuss three important tasks of recommender systems, and classify a set of appropriate well known evaluation metrics for each task. We demonstrate how using an improper evaluation metric can lead to the selection of an improper algorithm for the task of interest. We also discuss other important considerations when designing ofﬂine experiments.},
	language = {en},
	author = {Gunawardana, Asela and Shani, Guy},
	file = {PDF:C\:\\Users\\vighn\\Zotero\\storage\\33MBRA3P\\Gunawardana and Shani - A Survey of Accuracy Evaluation Metrics of Recommendation Tasks.pdf:application/pdf},
}

@article{19,
	title = {A {Review} on {Evaluation} {Metrics} for {Data} {Classification} {Evaluations}},
	volume = {5},
	issn = {2231007X, 22309608},
	url = {http://www.aircconline.com/ijdkp/V5N2/5215ijdkp01.pdf},
	doi = {10.5121/ijdkp.2015.5201},
	abstract = {Evaluation metric plays a critical role in achieving the optimal classifier during the classification training. Thus, a selection of suitable evaluation metric is an important key for discriminating and obtaining the optimal classifier. This paper systematically reviewed the related evaluation metrics that are specifically designed as a discriminator for optimizing generative classifier. Generally, many generative classifiers employ accuracy as a measure to discriminate the optimal solution during the classification training. However, the accuracy has several weaknesses which are less distinctiveness, less discriminability, less informativeness and bias to majority class data. This paper also briefly discusses other metrics that are specifically designed for discriminating the optimal solution. The shortcomings of these alternative metrics are also discussed. Finally, this paper suggests five important aspects that must be taken into consideration in constructing a new discriminator metric.},
	language = {en},
	number = {2},
	urldate = {2024-10-31},
	journal = {International Journal of Data Mining \& Knowledge Management Process},
	author = {M, Hossin and M.N, Sulaiman},
	month = mar,
	year = {2015},
	pages = {01--11},
	file = {PDF:C\:\\Users\\vighn\\Zotero\\storage\\27JDRSAS\\M and M.N - 2015 - A Review on Evaluation Metrics for Data Classification Evaluations.pdf:application/pdf},
}

@inproceedings{9,
	title = {{SVM} kernel functions for classification},
	url = {https://ieeexplore.ieee.org/abstract/document/6524743?casa_token=4S_i-YAeRcgAAAAA:5AyAgPEclZgpJH_RMpk4yCj6D3Z3Eo4rvRQLJfOYY4oBysOnxz5OlkcnBrXCEKWXIXip253dqA},
	doi = {10.1109/ICAdTE.2013.6524743},
	abstract = {A new generation learning system based on recent advances in statistical learning theory deliver state-of-the-art performance in real-world applications that is Support Vector Machines [2]. Applications such as text categorization, hand-written character recognition, image classification, bio-sequence analysis [9] etc for the classification and regression Most of the existing supervised classification methods are based on traditional statistics, which can provide ideal results when sample size is tending to infinity. However, only finite samples can be acquired in practice. In this paper, a novel learning method, Support Vector Machine (SVM), is applied on different data. This paper emphasizes the classification task with Support Vector Machine with different kernel function. It has several kernel functions including linear, polynomial and radial basis for performing classification [13].},
	urldate = {2024-10-31},
	booktitle = {2013 {International} {Conference} on {Advances} in {Technology} and {Engineering} ({ICATE})},
	author = {Patle, Arti and Chouhan, Deepak Singh},
	month = jan,
	year = {2013},
	keywords = {Accuracy, Data mining, feature, Kernel, Mathematical model, Polynomials, radial basis function, support vector, Support vector machines, Training},
	pages = {1--9},
	file = {Full Text PDF:C\:\\Users\\vighn\\Zotero\\storage\\BP99J257\\Patle and Chouhan - 2013 - SVM kernel functions for classification.pdf:application/pdf},
}

@article{5,
	title = {Environmental {Issues} {Relating} to {Greenhouse} {Carbon} {Dioxide} {Emissions} in the {World}},
	volume = {21},
	issn = {0144-5987},
	url = {https://doi.org/10.1260/014459803322986286},
	doi = {10.1260/014459803322986286},
	abstract = {Emissions of CO2 caused by human activity are generally considered the most important single source of potential future warming. States have played a leading role in protecting the environment by reducing emission of greenhouse gases (GHGs). State emissions are significant on a global scale. CO2 and CO are main GHGs associated with global warning. At the present time, coal is responsible for 30–40\% of the world CO2 emissions from fossil fuels. Carbon assessments can play an important role in a strategy to control carbon dioxide emissions while raising revenue.},
	language = {en},
	number = {5},
	urldate = {2024-10-31},
	journal = {Energy Exploration \& Exploitation},
	author = {Balat, Mustafa and Balat, Havva and Acici, Neslihan},
	month = oct,
	year = {2003},
	note = {Publisher: SAGE Publications Ltd STM},
	pages = {457--473},
	file = {SAGE PDF Full Text:C\:\\Users\\vighn\\Zotero\\storage\\2AW6RTRI\\Balat et al. - 2003 - Environmental Issues Relating to Greenhouse Carbon Dioxide Emissions in the World.pdf:application/pdf},
}

@article{12,
	title = {Population {Growth} and {Global} {Carbon} {Dioxide} {Emissions}},
	abstract = {Previous studies on the determinants of carbon dioxide emissions have primarily focused on the role of affluence. The impact of population growth on carbon dioxide emissions has received less attention. This paper takes a step forward providing such empirical evidence, using a data set of 93 countries for the period of 1975-1996. The paper has following findings. (1) Population growth has been one of the major driving forces behind increasing carbon dioxide emissions worldwide over the last two decades. It is estimated that half of increase in emissions by 2025 will be contributed by future population growth alone. (2) Rising income levels have been associated with a monotonically upward shift in emissions. \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ The findings, interpretations, and conclusions are entirely those of the author. They do not necessarily represent the views of the World Bank, its Executive Directors, or the countries they represent. I thank Bob Cull, Phillip Keefer, Steve Knack, Brian O’Neill, and William Martin for very helpful comments. Author’s email address: ashi@worldbank.org.},
	language = {en},
	author = {Shi, Anqing},
	file = {PDF:C\:\\Users\\vighn\\Zotero\\storage\\35GWP5K3\\Shi - Population Growth and Global Carbon Dioxide Emissions.pdf:application/pdf},
}

@article{4,
	title = {Spatial-temporal evolution characteristics and spillover effects of carbon emissions from shipping trade in {EU} coastal countries},
	volume = {250},
	issn = {0964-5691},
	url = {https://www.sciencedirect.com/science/article/pii/S0964569124000140},
	doi = {10.1016/j.ocecoaman.2024.107029},
	abstract = {The shipping industry is responsible for 80\% of world's trade and transportation, plays a pivotal role in the global economy, even now facing a decarbonylative trial. With the challenges of climate change, analyzing the spatial-temporal characteristics and driving factors of carbon emissions from international shipping has become a prerequisite for controlling greenhouse gas emissions, especially carbon dioxide emissions. On this basis, this study introduces the data of 19 coastal countries in the European Union (EU) to build the weighting matrices and spatial Durbin model to reflect the spatial-temporal characteristics and driving factors. The observations reflect that the carbon emissions from shipping trade in the EU coastal countries have a positive spatial correlation and spatial clustering. Additionally, the driving factors not only affect the domestic region, but also cause the spillover effect. Further, the spatial spillover effects of driving factors still exist in both the short-term and long-term perspectives, where that in the short-term perspective is more obvious.},
	urldate = {2024-10-31},
	journal = {Ocean \& Coastal Management},
	author = {Xu, Lang and Yang, Zhihui and Chen, Jihong and Zou, Zeyuan and Wang, Yang},
	month = apr,
	year = {2024},
	keywords = {Carbon emissions, Moran's index, Shipping trade, Spatial-temporal characteristics},
	pages = {107029},
	file = {ScienceDirect Snapshot:C\:\\Users\\vighn\\Zotero\\storage\\57D8PZP7\\S0964569124000140.html:text/html},
}

@misc{8,
	title = {Freight {Transportation} {\textbar} {MIT} {Climate} {Portal}},
	url = {https://climate.mit.edu/explainers/freight-transportation},
	urldate = {2024-09-19},
}
@misc{6,
	title = {{AIV}\_BTH.{SE}\_Flytnow - {Google} {Drive}},
	url = {https://drive.google.com/drive/folders/1x45VUmqEOERXg72d1N-VojuvE5K5Zx0b},
	urldate = {2024-09-19},
	file = {AIV_BTH.SE_Flytnow - Google Drive:C\:\\Users\\vighn\\Zotero\\storage\\EY3629P9\\1x45VUmqEOERXg72d1N-VojuvE5K5Zx0b.html:text/html},
}
@article{2,
	title = {Spatial-temporal evolution characteristics and spillover effects of carbon emissions from shipping trade in {EU} coastal countries},
	volume = {250},
	issn = {0964-5691},
	url = {https://www.sciencedirect.com/science/article/pii/S0964569124000140},
	doi = {10.1016/j.ocecoaman.2024.107029},
	abstract = {The shipping industry is responsible for 80\% of world's trade and transportation, plays a pivotal role in the global economy, even now facing a decarbonylative trial. With the challenges of climate change, analyzing the spatial-temporal characteristics and driving factors of carbon emissions from international shipping has become a prerequisite for controlling greenhouse gas emissions, especially carbon dioxide emissions. On this basis, this study introduces the data of 19 coastal countries in the European Union (EU) to build the weighting matrices and spatial Durbin model to reflect the spatial-temporal characteristics and driving factors. The observations reflect that the carbon emissions from shipping trade in the EU coastal countries have a positive spatial correlation and spatial clustering. Additionally, the driving factors not only affect the domestic region, but also cause the spillover effect. Further, the spatial spillover effects of driving factors still exist in both the short-term and long-term perspectives, where that in the short-term perspective is more obvious.},
	urldate = {2024-10-31},
	journal = {Ocean \& Coastal Management},
	author = {Xu, Lang and Yang, Zhihui and Chen, Jihong and Zou, Zeyuan and Wang, Yang},
	month = apr,
	year = {2024},
	keywords = {Carbon emissions, Moran's index, Shipping trade, Spatial-temporal characteristics},
	pages = {107029},
}

@misc{19,
	title = {Performance {Metrics} ({Error} {Measures}) in {Machine} {Learning} {Regression}, {Forecasting} and {Prognostics}: {Properties} and {Typology}},
	shorttitle = {Performance {Metrics} ({Error} {Measures}) in {Machine} {Learning} {Regression}, {Forecasting} and {Prognostics}},
	url = {http://arxiv.org/abs/1809.03006},
	abstract = {Performance metrics (error measures) are vital components of the evaluation frameworks in various fields. The intention of this study was to overview of a variety of performance metrics and approaches to their classification. The main goal of the study was to develop a typology that will help to improve our knowledge and understanding of metrics and facilitate their selection in machine learning regression, forecasting and prognostics. Based on the analysis of the structure of numerous performance metrics, we propose a framework of metrics which includes four (4) categories: primary metrics, extended metrics, composite metrics, and hybrid sets of metrics. The paper identified three (3) key components (dimensions) that determine the structure and properties of primary metrics: method of determining point distance, method of normalization, method of aggregation of point distances over a data set.},
	urldate = {2024-10-31},
	publisher = {arXiv},
	author = {Botchkarev, Alexei},
	month = sep,
	year = {2018},
	note = {arXiv:1809.03006},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Methodology},
	file = {Full Text PDF:C\:\\Users\\vighn\\Zotero\\storage\\HZTNMME7\\Botchkarev - 2018 - Performance Metrics (Error Measures) in Machine Learning Regression, Forecasting and Prognostics Pr.pdf:application/pdf;Snapshot:C\:\\Users\\vighn\\Zotero\\storage\\CKWB7USV\\1809.html:text/html},
}
